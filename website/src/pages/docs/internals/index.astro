---
import DocsLayout from '../../../layouts/DocsLayout.astro';
---

<DocsLayout title="Language Internals">
  <h1>Language Internals</h1>

  <p class="lead">
    Deep dive into how MDZ works under the hood: parser architecture, AST structure, validation pipeline, compiler internals, and LSP integration.
  </p>

  <h2>Architecture Overview</h2>

  <p>
    When you run <code>mdz compile skill.mdz</code>, the following pipeline executes:
  </p>

  <ol>
    <li><strong>Lexer</strong> tokenizes the source into a stream of tokens</li>
    <li><strong>Parser</strong> builds an Abstract Syntax Tree (AST)</li>
    <li><strong>Compiler</strong> extracts metadata and validates</li>
    <li><strong>Output</strong> returns the original source (unchanged)</li>
    <li><strong>LSP</strong> provides IDE features during editing</li>
  </ol>

  <p>
    This architecture ensures MDZ skills are validated at build time while remaining readable by both humans and LLMs at runtime.
  </p>

  <h3>Core Principle: Source = Output</h3>

  <p>
    <strong>The LLM sees exactly what you write.</strong> There is no transformation layer between source and execution. The compiler:
  </p>

  <ul>
    <li>Parses the source into AST</li>
    <li>Extracts metadata and validates</li>
    <li>Returns the original source unchanged</li>
    <li>Provides diagnostics and dependency information</li>
  </ul>

  <h2>Internals Documentation</h2>

  <p>
    Explore the detailed documentation for each component:
  </p>

  <ul>
    <li><a href="/docs/internals/ast">AST Structure</a> — Parser architecture, lexer tokens, recursive descent parsing, and AST node types</li>
    <li><a href="/docs/internals/compilation">Compilation</a> — Compiler internals, metadata extraction, skill registry, and dependency graph</li>
    <li><a href="/docs/internals/validation">Validation</a> — Multi-stage validation pipeline with concrete diagnostic examples</li>
    <li><a href="/docs/internals/terminology">Terminology</a> — Glossary of MDZ syntax elements and canonical terms</li>
  </ul>

  <h2>Implementation Challenges</h2>

  <p>
    Key challenges encountered during MDZ development and their solutions:
  </p>

  <h3>Indentation-Aware Parsing</h3>

  <p>
    <strong>Challenge:</strong> Python-style significant whitespace is complex to parse correctly, especially with mixed tabs/spaces and error recovery.
  </p>

  <p>
    <strong>Solution:</strong> Indentation stack with explicit INDENT/DEDENT tokens, panic-mode error recovery, and clear error messages for inconsistent indentation.
  </p>

  <h3>Source = Output Constraint</h3>

  <p>
    <strong>Challenge:</strong> Validator-first approach requires preserving exact source formatting while still validating semantics.
  </p>

  <p>
    <strong>Solution:</strong> No transformation pipeline - compiler only extracts metadata and validates, returns original source unchanged.
  </p>

  <h3>Skill Registry Management</h3>

  <p>
    <strong>Challenge:</strong> Cross-skill validation requires loading and caching multiple ASTs, with potential for stale data and performance issues.
  </p>

  <p>
    <strong>Solution:</strong> Lazy loading with invalidation on file changes, workspace-wide registry with efficient lookup, and graceful degradation when skills are unavailable.
  </p>

  <h3>LLM-Friendly Error Messages</h3>

  <p>
    <strong>Challenge:</strong> Technical error messages are confusing for LLM authors who may not understand compiler internals.
  </p>

  <p>
    <strong>Solution:</strong> Context-aware error messages with suggestions, examples of correct syntax, and progressive disclosure of technical details.
  </p>

  <h3>Real-Time IDE Performance</h3>

  <p>
    <strong>Challenge:</strong> LSP must provide instant feedback during typing, but full validation can be expensive.
  </p>

  <p>
    <strong>Solution:</strong> Incremental parsing with AST diffing, cached validation results, and prioritized error reporting (syntax > types > references).
  </p>

  <h2>Contributor Pathways</h2>

  <p>
    MDZ is designed to be extensible. Here are key areas where contributors can add functionality:
  </p>

  <h3>Extending the Lexer</h3>

  <p>
    To add a new token type (e.g., a new keyword):
  </p>

  <ol>
    <li>Add token type to <code>TokenType</code> union in <code>lexer.ts</code></li>
    <li>Add pattern matching in <code>scanIdentOrKeyword()</code></li>
    <li>Handle in parser grammar productions</li>
    <li>Add syntax highlighting rules to editor extensions</li>
  </ol>

  <h3>Adding AST Nodes</h3>

  <p>
    To add new language constructs:
  </p>

  <ol>
    <li>Define AST interface in <code>ast.ts</code></li>
    <li>Add to appropriate union type (<code>Block</code>, <code>Expression</code>, etc.)</li>
    <li>Implement parser production in <code>parser.ts</code></li>
    <li>Add validation logic in <code>compiler.ts</code></li>
    <li>Update LSP handlers for IDE features</li>
  </ol>

  <h3>Validation Rules</h3>

  <p>
    Extend validation by adding new stages or modifying existing ones:
  </p>

  <ul>
    <li><strong>Type checking:</strong> Add custom type rules beyond basic resolution</li>
    <li><strong>Contract validation:</strong> Verify delegation parameter matching</li>
    <li><strong>Cross-skill analysis:</strong> Validate data flow between skills</li>
  </ul>

  <h3>LSP Protocol Integration</h3>

  <p>
    IDE features are implemented as LSP message handlers:
  </p>

  <ul>
    <li><strong>textDocument/completion:</strong> Add context-aware suggestions</li>
    <li><strong>textDocument/hover:</strong> Provide type/variable information</li>
    <li><strong>textDocument/definition:</strong> Implement go-to-definition for new constructs</li>
  </ul>
</DocsLayout>
